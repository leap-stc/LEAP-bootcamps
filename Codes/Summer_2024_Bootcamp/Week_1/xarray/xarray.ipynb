{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is adapted from Ryan Abernathey lecture on: https://github.com/earth-env-data-science/earth-env-data-science-book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xarray Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarray data structures\n",
    "\n",
    "Like Pandas, xarray has two fundamental data structures:\n",
    "* a `DataArray`, which holds a single multi-dimensional variable and its coordinates\n",
    "* a `Dataset`, which holds multiple variables that potentially share the same coordinates\n",
    "\n",
    "### DataArray\n",
    "\n",
    "A `DataArray` has four essential attributes:\n",
    "* `values`: a `numpy.ndarray` holding the array’s values\n",
    "* `dims`: dimension names for each axis (e.g., `('x', 'y', 'z')`)\n",
    "* `coords`: a dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings)\n",
    "* `attrs`: an `OrderedDict` to hold arbitrary metadata (attributes)\n",
    "\n",
    "Let's start by constructing some DataArrays manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple DataArray without dimensions or coordinates isn't much use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a data-array from Python array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a dimension name..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a dimension name using `dims` argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But things get most interesting when we add a coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add coordinates using the `coords` argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This coordinate has been used to create an _index_, which works very similar to a Pandas index.\n",
    "In fact, under the hood, Xarray just reuses Pandas indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray has built-in plotting, like pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.plot(marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional DataArray\n",
    "\n",
    "If we are just dealing with 1D data, Pandas and Xarray have very similar capabilities. Xarray's real potential comes with multidimensional data.\n",
    "\n",
    "Let's go back to the multidimensional ARGO data we loaded in the numpy lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch\n",
    "url = \"https://www.ldeo.columbia.edu/~rpa/float_data_4901412.zip\"\n",
    "files = pooch.retrieve(url, processor=pooch.Unzip(), known_hash=\"2a703c720302c682f1662181d329c9f22f9f10e1539dc2d6082160a469165009\")\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will manually load each of these variables into a numpy array.\n",
    "If this seems repetitive and inefficient, that's the point!\n",
    "NumPy itself is not meant for managing groups of inter-related arrays.\n",
    "That's what Xarray is for!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.load(files[0])\n",
    "S = np.load(files[1])\n",
    "T = np.load(files[2])\n",
    "date = np.load(files[3])\n",
    "lat = np.load(files[4])\n",
    "levels = np.load(files[5])\n",
    "lon = np.load(files[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's organize the data and coordinates of the salinity variable into a DataArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_salinity = xr.DataArray(S, dims=['level', 'date'],\n",
    "                           coords={'level': levels,\n",
    "                                   'date': date},)\n",
    "da_salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot da_salinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes can be used to store metadata. What metadata should you store? The [CF Conventions](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.7/cf-conventions.html#_description_of_the_data) are a great resource for thinking about climate metadata. Below we define two of the required CF-conventions attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_salinity.attrs['units'] = 'PSU'\n",
    "da_salinity.attrs['standard_name'] = 'sea_water_salinity'\n",
    "da_salinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we plot the data again, the name and units are automatically attached to the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_salinity.plot(yincrease=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Datasets\n",
    "\n",
    "A Dataset holds many DataArrays which potentially can share coordinates. In analogy to pandas:\n",
    "\n",
    "    pandas.Series : pandas.Dataframe :: xarray.DataArray : xarray.Dataset\n",
    "    \n",
    "Constructing Datasets manually is a bit more involved in terms of syntax. The Dataset constructor takes three arguments:\n",
    "\n",
    "* `data_vars` should be a dictionary with each key as the name of the variable and each value as one of:\n",
    "  * A `DataArray` or Variable\n",
    "  * A tuple of the form `(dims, data[, attrs])`, which is converted into arguments for Variable\n",
    "  * A pandas object, which is converted into a `DataArray`\n",
    "  * A 1D array or list, which is interpreted as values for a one dimensional coordinate variable along the same dimension as it’s name\n",
    "* `coords` should be a dictionary of the same form as data_vars.\n",
    "* `attrs` should be a dictionary.\n",
    "\n",
    "Let's put together a Dataset with temperature, salinity and pressure all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo = xr.Dataset(\n",
    "    data_vars={\n",
    "        'salinity':    (('level', 'date'), S),\n",
    "        'temperature': (('level', 'date'), T),\n",
    "        'pressure':    (('level', 'date'), P)\n",
    "    },\n",
    "    coords={\n",
    "        'level': levels,\n",
    "        'date': date\n",
    "    }\n",
    ")\n",
    "argo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about lon and lat? We forgot them in the creation process, but we can add them after the fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo.coords['lon'] = lon\n",
    "argo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was not quite right...we want lon to have dimension `date`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del argo['lon']\n",
    "argo.coords['lon'] = ('date', lon)\n",
    "argo.coords['lat'] = ('date', lat)\n",
    "argo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates vs. Data Variables\n",
    "\n",
    "Data variables can be modified through arithmentic operations or other functions. Coordinates are always keept the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: operation on the Dataset argo * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly lon and lat are coordinates rather than data variables. We can change their status as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo = argo.set_coords(['lon', 'lat'])\n",
    "argo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `*` symbol in the representation above indicates that `level` and `date` are \"dimension coordinates\" (they describe the coordinates associated with data variable axes) while `lon` and `lat` are \"non-dimension coordinates\". We can make any variable a non-dimension coordiante.\n",
    "\n",
    "Alternatively, we could have assigned directly to coords as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo.coords['lon'] = ('date', lon)\n",
    "argo.coords['lat'] = ('date', lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Data (Indexing)\n",
    "\n",
    "We can always use regular numpy indexing and slicing on DataArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo.salinity[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo.salinity[2].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo.salinity[:, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo.salinity[:, 10].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is often much more powerful to use xarray's `.sel()` method to use label-based indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: select level=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: select date='2012-10-22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot with y='level' and yincrease=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.sel()` also supports slicing. Unfortunately we have to use a somewhat awkward syntax, but it still works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: select date in slice('2012-10-01', '2012-12-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the sliced dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.sel()` also works on the whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo.sel(date='2012-10-22')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation\n",
    "\n",
    "Xarray dataarrays and datasets work seamlessly with arithmetic operators and numpy array functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: convert from C to Kelvin by adding 273.15\n",
    "# TODO: plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine multiple xarray datasets in arithemtic operations\n",
    "\n",
    "$buoyancy = g * (2e^{-4} * temperature - 7e^{-4} * salinity)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute buoyancy and plot\n",
    "g = 9.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting, Aligment, and Combining Data\n",
    "\n",
    "### Broadcasting\n",
    "\n",
    "Broadcasting arrays in numpy is a nightmare. It is much easier when the data axes are labeled!\n",
    "\n",
    "This is a useless calculation, but it illustrates how perfoming an operation on arrays with differenty coordinates will result in automatic broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_times_lat = argo.level * argo.lat\n",
    "level_times_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_times_lat.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment\n",
    "\n",
    "If you try to perform operations on DataArrays that share a dimension name, Xarray will try to _align_ them first.\n",
    "This works nearly identically to Pandas, except that there can be multiple dimensions to align over.\n",
    "\n",
    "To see how alignment works, we will create some subsets of our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_surf = argo.salinity.isel(level=slice(0, 20))\n",
    "sa_mid = argo.salinity.isel(level=slice(10, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, when we combine multiple arrays in mathematical operations, Xarray performs an \"inner join\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sa_surf * sa_mid).level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can override this behavior by manually aligning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_surf_outer, sa_mid_outer = xr.align(sa_surf, sa_mid, join='outer')\n",
    "sa_surf_outer.level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, missing data (NaNs) have been filled in where the array was extended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_surf_outer.plot(yincrease=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combing Data: Concat and Merge\n",
    "\n",
    "The ability to combine many smaller arrays into a single big Dataset is one of the main advantages of Xarray.\n",
    "To take advantage of this, we need to learn two operations that help us combine data:\n",
    "- `xr.contact`: to concatenate multiple arrays into one bigger array along their dimensions\n",
    "- `xr.merge`: to combine multiple different arrays into a dataset\n",
    "\n",
    "First let's look at concat. Let's re-combine the subsetted data from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: concat sa_surf and sa_mid along the level dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "Xarray won't check the values of the coordinates before `concat`. It will just stick everything together into a new array.\n",
    "```\n",
    "\n",
    "In this case, we had overlapping data. We can see this by looking at the `level` coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check level coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot to see duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also concat data along a _new_ dimension, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: concat along new dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data were aligned using an _outer_ join along the non-concat dimensions.\n",
    "\n",
    "Instead of specifying a new dimension name, we can pass a new Pandas index object explicitly to `concat`.\n",
    "This will create a new dimension coordinate and corresponding index.\n",
    "\n",
    "We can merge both DataArrays and Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge([argo.salinity, argo.temperature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data are not aligned, they will be aligned before merge.\n",
    "We can specify the join options in `merge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge([\n",
    "    argo.salinity.sel(level=slice(0, 30)),\n",
    "    argo.temperature.sel(level=slice(30, None))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pass in the join='left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compare with join='right'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reductions\n",
    "\n",
    "Just like in numpy, we can reduce xarray DataArrays along any number of axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute temperature mean along axis=0 (level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute temperature along axis=1 (date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, rather than performing reductions on axes (as in numpy), we can perform them on dimensions. This turns out to be a huge convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute Dataset mean along dim='date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the mean of salinity after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute Dataset std along dim='date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the std of salinity after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Reductions\n",
    "\n",
    "Sometimes we want to perform a reduction (e.g. a mean) where we assign different weight factors to each point in the array.\n",
    "Xarray supports this via [weighted array reductions](http://xarray.pydata.org/en/stable/user-guide/computation.html#weighted-array-reductions).\n",
    "\n",
    "As a toy example, imagine we want to weight values in the upper ocean more than the lower ocean.\n",
    "We could imagine creating a weight array exponentially proportional to pressure as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pressure = argo.pressure.mean(dim='date')\n",
    "p0 = 250  # dbat\n",
    "weights = np.exp(-mean_pressure / p0)\n",
    "weights.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted mean over the `level` dimensions is calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_weighted_mean = argo.temperature.weighted(weights).mean('level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to the unweighted mean, we see the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_weighted_mean.plot(label='weighted')\n",
    "argo.temperature.mean(dim='level').plot(label='unweighted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading Data from netCDF Files\n",
    "\n",
    "NetCDF (Network Common Data Format) is the most widely used format for distributing geoscience data. NetCDF is maintained by the [Unidata](https://www.unidata.ucar.edu/) organization.\n",
    "\n",
    "Below we quote from the [NetCDF website](https://www.unidata.ucar.edu/software/netcdf/docs/faq.html#whatisit):\n",
    "\n",
    ">NetCDF (network Common Data Form) is a set of interfaces for array-oriented data access and a freely distributed collection of data access libraries for C, Fortran, C++, Java, and other languages. The netCDF libraries support a machine-independent format for representing scientific data. Together, the interfaces, libraries, and format support the creation, access, and sharing of scientific data.\n",
    ">\n",
    ">NetCDF data is:\n",
    ">\n",
    "> - Self-Describing. A netCDF file includes information about the data it contains.\n",
    "> - Portable. A netCDF file can be accessed by computers with different ways of storing integers, characters, and floating-point numbers.\n",
    "> - Scalable. A small subset of a large dataset may be accessed efficiently.\n",
    "> - Appendable. Data may be appended to a properly structured netCDF file without copying the dataset or redefining its structure.\n",
    "> - Sharable. One writer and multiple readers may simultaneously access the same netCDF file.\n",
    "> - Archivable. Access to all earlier forms of netCDF data will be supported by current and future versions of the software.\n",
    "\n",
    "Xarray was designed to make reading netCDF files in python as easy, powerful, and flexible as possible. (See [xarray netCDF docs](http://xarray.pydata.org/en/latest/io.html#netcdf) for more details.)\n",
    "\n",
    "Below we download and load some the NASA [GISSTemp](https://data.giss.nasa.gov/gistemp/) global temperature anomaly dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gistemp_file = pooch.retrieve(\n",
    "    'https://data.giss.nasa.gov/pub/gistemp/gistemp1200_GHCNv4_ERSSTv5.nc.gz',\n",
    "    known_hash='5cd1466548781e1bf0bf404db47c84e2f6fd69075c5d01802644ca644f410764',\n",
    "    processor=pooch.Decompress(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(gistemp_file)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tempanomaly.isel(time=-1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tempanomaly.mean(dim=('lon', 'lat')).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
